{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n"
     ]
    }
   ],
   "source": [
    "# File: proc_ont.py\n",
    "# Description:\n",
    "# This file accepts user made strings as input.\n",
    "# It processes the input to clean and extract keywords from it.\n",
    "# Then the tool proceeds with extracting the ontology concept for the keyword.\n",
    "# Afterwards, the concepts get queried to a search tool (default is GeoNetwork).\n",
    "# The output is converted to human readable format.\n",
    "# Author: Mitchell Verhaar\n",
    "\n",
    "from owlready2 import *\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "import requests\n",
    "\n",
    "class Ontology_Parser:\n",
    "\n",
    "    def __init__(self, ont_list, filt_punc = False, limit = 5):\n",
    "        ### Initializes the class instance\n",
    "        self.ont_list = ont_list\n",
    "        self.stopwords = set(stopwords.words('english'))\n",
    "        self.punc_table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "        self.filter_punc = filt_punc\n",
    "        self.ont_dict_split = {}\n",
    "        self.ont_dict_count = {}\n",
    "        self.query_ip = '212.189.145.37:8080'\n",
    "        self.limit = limit\n",
    "\n",
    "    def load_ontologies(self):\n",
    "        ### This function loads the ontologies given to the class at the initialization\n",
    "        for ont in self.ont_list:\n",
    "            try:\n",
    "                proc_ont = get_ontology(ont).load()\n",
    "                self.ont_dict_split[(proc_ont.name, proc_ont)] = {}\n",
    "            except Exception as err:\n",
    "                print(\"Cannot load ontology: \" + ont + \"\\nDue to error: \" + str(err))\n",
    "    \n",
    "    def process_input(self, u_input = None):\n",
    "        ### This function cleans and filters the user input into usable input terms\n",
    "        if u_input and self.filter_punc:\n",
    "            return [re.sub(r\"\\W+$\", \"\", re.sub(r\"\\W+\\b\", \" \", word.lower())) for word in u_input.split(',') if word.lower() not in self.stopwords]\n",
    "        elif u_input and not self.filter_punc:  \n",
    "            return [word.lower() for word in u_input.split(',') if word.lower() not in self.stopwords]\n",
    "        elif not u_input and self.filter_punc:\n",
    "            return [re.sub(r\"\\W+$\", \"\", re.sub(r\"\\W+\\b\", \" \", word.lower())) for word in input(\"Enter the desired query here: \").split(',') if word.lower() not in self.stopwords]\n",
    "        else:\n",
    "            return [word.lower() for word in input(\"Enter the desired query here: \").split(',') if word.lower() not in self.stopwords]\n",
    "        \n",
    "    def search(self, u_input = None):\n",
    "        ### This function performs the searching of ontologies given a set of input terms\n",
    "        proc_input = self.process_input(u_input)\n",
    "        if '' not in proc_input:\n",
    "            for name, ont in self.ont_dict_split.keys():\n",
    "                for term in proc_input:\n",
    "                    ont_concept = ont.search_one(label = term)\n",
    "                    if ont_concept:\n",
    "                        self.add_concepts(ont_concept, name, ont)\n",
    "                    else:\n",
    "                        print(\"No ontological concepts have been found\")\n",
    "        else:\n",
    "            print(\"Input must be provided!\")\n",
    "    \n",
    "    def add_concepts(self, result, name, ont):\n",
    "        ### Adds concepts to the original query keywords\n",
    "        self.ont_dict_split[(name, ont)][result.label[0]] = result\n",
    "        self.add_count(result.label[0])\n",
    "        for related_concepts in result.is_a:\n",
    "            if hasattr(related_concepts, 'label'):\n",
    "                    if related_concepts.label:\n",
    "                        print(related_concepts.label)\n",
    "                        self.ont_dict_split[(name, ont)][related_concepts.label[0]] = related_concepts\n",
    "                        self.add_count(related_concepts.label[0])\n",
    "            else:\n",
    "                if hasattr(related_concepts, 'value'):\n",
    "                    if related_concepts.value.label:\n",
    "                        print(related_concepts.value.label)\n",
    "                        self.ont_dict_split[(name, ont)][related_concepts.value.label[0]] = related_concepts.value\n",
    "                        self.add_count(related_concepts.value.label[0])\n",
    "            \n",
    "    def process_concepts(self):\n",
    "        ### This function converts the ontology output into a list sorted by most occurring concept\n",
    "        sorted_concepts = sorted(self.ont_dict_count.items(), key=lambda item: item[1])\n",
    "        return [concept[0] for concept in sorted_concepts]\n",
    "    \n",
    "    def add_count(self, label):\n",
    "        ### Adds term to stored dict\n",
    "        if label in self.ont_dict_count:\n",
    "            self.ont_dict_count[label] += 1\n",
    "        else:\n",
    "            self.ont_dict_count[label] = 1\n",
    "    \n",
    "    def send_query(self):\n",
    "        ### This function sends the ontology output to the search tool that is being used\n",
    "        ordered_query = ' '.join(self.process_concepts())\n",
    "        print(ordered_query)\n",
    "        if ordered_query:\n",
    "            try:\n",
    "                url = \"http://\" + self.query_ip + \"/geonetwork/srv/eng/q?or=\" + ordered_query + \"&from=1&to=20&resultType=details&fast=index&_content_type=xml\"\n",
    "                response = requests.get(url)\n",
    "                print(response.content)\n",
    "                print(response.text)\n",
    "                with open(\"Search_Results/output_\" + ordered_query.replace(\" \", \"_\") + \".xml\", \"w+\") as f:\n",
    "                    f.write(response.text)\n",
    "                    print(\"Output saved to Search_Results/output_\" + ordered_query.replace(\" \", \"_\"))\n",
    "            except:\n",
    "                print(\"Connection to the search tool failed!\")\n",
    "        else:\n",
    "            print(\"No ontology concepts could be added, using original user query as input...\")\n",
    "    \n",
    "# Experiments to show keyword generations and connection to GeoNetwork\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the desired query here: Ocean\n",
      "['marine water body']\n",
      "['saline water body']\n",
      "['sea water']\n",
      "['marine water body']\n",
      "['saline water body']\n",
      "['sea water']\n",
      "ocean marine water body saline water body sea water\n",
      "Connection to the search tool failed!\n"
     ]
    }
   ],
   "source": [
    "ont_parse = Ontology_Parser([\"http://purl.obolibrary.org/obo/envo.owl\", \"http://purl.obolibrary.org/obo/oba.owl\"], False)\n",
    "ont_parse.load_ontologies()\n",
    "ont_parse.search()\n",
    "\n",
    "ont_parse.send_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('envo', get_ontology(\"http://purl.obolibrary.org/obo/envo.owl#\")): {'ocean': obo.ENVO_00000015, 'marine water body': obo.ENVO_00001999, 'saline water body': obo.ENVO_01001319, 'sea water': obo.ENVO_00002149}, ('oba', get_ontology(\"http://purl.obolibrary.org/obo/oba.owl#\")): {'ocean': obo.ENVO_00000015, 'marine water body': obo.ENVO_00001999, 'saline water body': obo.ENVO_01001319, 'sea water': obo.ENVO_00002149}}\n",
      "{'ocean': 2, 'marine water body': 2, 'saline water body': 2, 'sea water': 2}\n"
     ]
    }
   ],
   "source": [
    "print(ont_parse.ont_dict_split)\n",
    "print(ont_parse.ont_dict_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"http://purl.obolibrary.org/obo/po.owl\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python37064bitbc436b90dab04c358fa0eaa6468e0142"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
